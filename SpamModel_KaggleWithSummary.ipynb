{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn  # All neural network modules, nn.Linear, nn.Conv2d, BatchNorm, Loss functions\n",
    "import torch.optim as optim  # For all Optimization algorithms, SGD, Adam, etc.\n",
    "import torch.nn.functional as F  # All functions that don't have any parameters\n",
    "from torch.utils.data import (DataLoader,)  # Gives easier dataset managment and creates mini batches\n",
    "#import torchvision  # torch package for vision related things\n",
    "#import torchvision.datasets as datasets  # Has standard datasets we can import in a nice way\n",
    "#import torchvision.transforms as transforms\n",
    "import pandas as pd\n",
    "import random\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, make_scorer\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from tqdm.auto import tqdm\n",
    "from transformers import DistilBertTokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Loading\n",
    "Grabbing the combined dataset and including the summary "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the downloaded Youtube01-Psy.csv file into train, validation and test sets\n",
    "data = pd.read_csv('SpamDataset/Youtube05-Combined.csv')\n",
    "# data = pd.read_csv('TSwift_ShakeItOff_Spam.csv')\n",
    "data = data.sample(frac=1).reset_index(drop=True)  # Shuffle the data\n",
    "train_data = data[:int(0.7*len(data))]\n",
    "val_data = data[int(0.7*len(data)):int(0.85*len(data))]\n",
    "test_data = data[int(0.85*len(data)):]\n",
    "\n",
    "# Tokenize the data using distillbert\n",
    "tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')\n",
    "\n",
    "# Turn pd dataframe into a tokenized PyTorch dataset that DataLoader can use via the SpamDataset class\n",
    "class CommentSummaryDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.data.iloc[idx]\n",
    "\n",
    "        comment_tokens = row['CONTENT'] + ' ' + row['SUMMARY']\n",
    "        label = row['CLASS']\n",
    "        return comment_tokens, label\n",
    "    \n",
    "    def collate_fn(self, batch):\n",
    "        comments = [row[0] for row in batch]\n",
    "        labels = [row[1] for row in batch]\n",
    "        tokens = tokenizer.batch_encode_plus(comments, truncation=True, padding='max_length', max_length=100, return_tensors='pt')\n",
    "        return tokens,  torch.tensor(labels)\n",
    "    \n",
    "class SummaryCommentDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.data.iloc[idx]\n",
    "        comment_tokens = row['SUMMARY'] + ' ' + row['CONTENT'] \n",
    "        label = row['CLASS']\n",
    "        return comment_tokens, label\n",
    "    \n",
    "    def collate_fn(self, batch):\n",
    "        comments = [row[0] for row in batch]\n",
    "        labels = [row[1] for row in batch]\n",
    "        tokens = tokenizer.batch_encode_plus(comments, truncation=True, padding='max_length', max_length=100, return_tensors='pt')\n",
    "        return tokens,  torch.tensor(labels)\n",
    "    \n",
    "fw_train_dataset = CommentSummaryDataset(train_data)\n",
    "fw_val_dataset = CommentSummaryDataset(val_data)\n",
    "fw_test_dataset = CommentSummaryDataset(test_data)\n",
    "\n",
    "bw_train_dataset = SummaryCommentDataset(train_data)\n",
    "bw_val_dataset = SummaryCommentDataset(val_data)\n",
    "bw_test_dataset = SummaryCommentDataset(test_data)\n",
    "\n",
    "\n",
    "# Load Data and collate it\n",
    "batch_size = 64\n",
    "fw_train_loader = DataLoader(fw_train_dataset, batch_size=batch_size, shuffle=True, collate_fn=fw_train_dataset.collate_fn)\n",
    "fw_val_loader = DataLoader(fw_val_dataset, batch_size=batch_size, shuffle=True, collate_fn=fw_val_dataset.collate_fn)\n",
    "fw_test_loader = DataLoader(fw_test_dataset, batch_size=batch_size, shuffle=True, collate_fn=fw_test_dataset.collate_fn)\n",
    "\n",
    "bw_train_loader = DataLoader(bw_train_dataset, batch_size=batch_size, shuffle=True, collate_fn=bw_train_dataset.collate_fn)\n",
    "bw_val_loader = DataLoader(bw_val_dataset, batch_size=batch_size, shuffle=True, collate_fn=bw_val_dataset.collate_fn)\n",
    "bw_test_loader = DataLoader(bw_test_dataset, batch_size=batch_size, shuffle=True, collate_fn=bw_test_dataset.collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "({'input_ids': tensor([[  101,  2066,  3531,  ...,     0,     0,     0],\n",
      "        [  101,  2045,  1045,  ...,     0,     0,     0],\n",
      "        [  101, 10166,  7486,  ..., 11333,  2912,   102],\n",
      "        ...,\n",
      "        [  101,  4824,  1014,  ...,     0,     0,     0],\n",
      "        [  101,  8840, 13669,  ...,     0,     0,     0],\n",
      "        [  101, 10587,  4756,  ...,     0,     0,     0]]), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 1, 1, 1],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0]])}, tensor([1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0,\n",
      "        1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1,\n",
      "        1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1]))\n",
      "[CLS] like please eminem and rihanna's \" love the way you lie \" explores the complexities of toxic relationships. the music video depicts intense scenes of domestic turmoil, reflecting the song's raw emotion and honesty. eminem's powerful lyrics combined with rihanna's soulful vocals create a haunting portrayal of love, pain, and struggle. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n",
      "({'input_ids': tensor([[  101,  4202,  9170,  ...,     0,     0,     0],\n",
      "        [  101, 21146, 23630,  ...,     0,     0,     0],\n",
      "        [  101,  1048,  2213,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [  101, 12495, 25832,  ...,  2465,  4476,   102],\n",
      "        [  101, 12495, 25832,  ...,     0,     0,     0],\n",
      "        [  101,  8827,  2100,  ...,     0,     0,     0]]), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 1, 1, 1],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0]])}, tensor([0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n",
      "        0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0,\n",
      "        1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1]))\n",
      "[CLS] taylor swift's \" shake it off \" music video is a colorful, upbeat anthem celebrating self - confidence and positivity. with catchy lyrics and energetic choreography, swift embraces different dance styles and encourages listeners to shrug off negativity. the video's vibrant visuals and playful tone make it a feel - good pop sensation. just randomly click the music of taylor.. i miss the old music [UNK] [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n"
     ]
    }
   ],
   "source": [
    "# Print a random sample from the train_loader to confirm correct loading and tokenization\n",
    "sample = next(iter(fw_train_loader))\n",
    "print(sample)\n",
    "# Print decoded tokens for the sample\n",
    "decoded = tokenizer.decode(sample[0]['input_ids'][0])\n",
    "print(decoded)\n",
    "\n",
    "sample = next(iter(bw_train_loader))\n",
    "print(sample)\n",
    "# Print decoded tokens for the sample\n",
    "decoded = tokenizer.decode(sample[0]['input_ids'][0])\n",
    "print(decoded)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model\n",
    "- Model 1 - include Like count\n",
    "- Model 2 - include LLM evaluation of the video "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## The network includes an Embedding layer, an Attention layer, an LSTM layer and a Linear layer\n",
    "class CombinedLSTM(nn.Module):\n",
    "    def __init__(self, embedding_dict, embedding_size, hidden_size, num_layers, num_classes, dropout):\n",
    "        super(CombinedLSTM, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.embedding = nn.Embedding(embedding_dict, embedding_size)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.lstm = nn.LSTM(embedding_size, hidden_size, num_layers, batch_first=True, dropout=dropout)\n",
    "        self.attention = nn.Linear(hidden_size, 1)\n",
    "        self.fc = nn.Linear(hidden_size, num_classes)\n",
    "        \n",
    "    def forward(self, comment_sequence):\n",
    "        # comment_sequence: (batch_size, max_seq_length)\n",
    "        embedding = self.dropout(self.embedding(comment_sequence))\n",
    "        # embedding shape: (batch_size, max_seq_length, embedding_size)\n",
    "        output, (h_n, c_n) = self.lstm(embedding)\n",
    "        # output shape: (batch_size, max_seq_length, hidden_size)\n",
    "        # h_n shape: (num_layers, batch_size, hidden_size)\n",
    "        attention_weights = F.softmax(self.attention(output), dim=1)\n",
    "        # attention_weights shape: (batch_size, max_seq_length, 1)\n",
    "        out = torch.sum(attention_weights * output, dim=1)\n",
    "        # out shape: (batch_size, hidden_size)\n",
    "        out = self.fc(out)\n",
    "        # out shape: (batch_size, num_classes)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utility Functions to run validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validation\n",
    "def check_accuracy(loader, model):\n",
    "    num_correct = 0\n",
    "    num_samples = 0\n",
    "    predictions = []\n",
    "    targets = []\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for comments, target in loader:\n",
    "            comments = {key: value.to(device) for key, value in comments.items()}\n",
    "            target = target.to(device)\n",
    "\n",
    "            scores = model(comments['input_ids'])\n",
    "            _, predicted = scores.max(1)\n",
    "            # Store decoded original comments, model predictions and actual labels \n",
    "            num_correct += (predicted == target).sum()\n",
    "            num_samples += predicted.size(0)\n",
    "\n",
    "            predictions.extend(predicted.tolist())\n",
    "            targets.extend(target.tolist())\n",
    "\n",
    "    # model.train()\n",
    "    accuracy = num_correct/num_samples\n",
    "    return accuracy, predictions, targets\n",
    "\n",
    "def results(model, train_loader, val_loader, test_loader,):\n",
    "    train_acc, train_preds, train_targets = check_accuracy(train_loader, model)\n",
    "    val_acc, val_preds, val_targets = check_accuracy(val_loader, model)\n",
    "    test_acc, test_preds, test_targets = check_accuracy(test_loader, model)\n",
    "\n",
    "    print(f'Train accuracy: {train_acc}')\n",
    "    print(f'Validation accuracy: {val_acc}')\n",
    "    print(f'Test accuracy: {test_acc}')\n",
    "\n",
    "    train_cm = confusion_matrix(train_targets, train_preds)\n",
    "    val_cm = confusion_matrix(val_targets, val_preds)\n",
    "    test_cm = confusion_matrix(test_targets, test_preds)\n",
    "\n",
    "    print(f'Train Confusion Matrix:\\n{train_cm}')\n",
    "    print(f'Validation Confusion Matrix:\\n{val_cm}')\n",
    "    print(f'Test Confusion Matrix:\\n{test_cm}')\n",
    "\n",
    "    # Classification report\n",
    "    train_report = classification_report(train_targets, train_preds)\n",
    "    val_report = classification_report(val_targets, val_preds)\n",
    "    test_report = classification_report(test_targets, test_preds)\n",
    "\n",
    "    print(f'Train Classification Report:\\n{train_report}')\n",
    "    print(f'Validation Classification Report:\\n{val_report}')\n",
    "    print(f'Test Classification Report:\\n{test_report}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e3c00e88b48488981262c0dec93cdee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/28 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15, Loss: 0.5778723359107971\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ca49c433eacb4915b84c4ac5a0263e70",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/28 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/15, Loss: 0.37204328179359436\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a4443e2c27941c0bec1586feb3e8bb6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/28 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/15, Loss: 0.4214445650577545\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b74988f9a6914a3da84fc10b2cf66f4b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/28 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/15, Loss: 0.3121963441371918\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ccc3bd2935b54f689798fe67a9f447ca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/28 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/15, Loss: 0.2853788435459137\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ed8770081b0444109ce484a40707ba1b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/28 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/15, Loss: 0.23406155407428741\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f4701c0b08af42e090010ab1d8a8a379",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/28 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/15, Loss: 0.24815143644809723\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b5e949153ce0431aae2b042519b07571",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/28 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/15, Loss: 0.33871129155158997\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1bae4f46567243a58a7696c38e8b4785",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/28 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/15, Loss: 0.14390529692173004\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "90dfa2efa7d14b40b04838150454f0c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/28 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/15, Loss: 0.0796523317694664\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ecae4e7795a04e3aae7e9c656338d108",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/28 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/15, Loss: 0.07777215540409088\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "72cb2cd35bda42579117d0ccd5c9ba2f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/28 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/15, Loss: 0.09596133232116699\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0340dde6bd284d8281ea90e3a6d1ff42",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/28 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/15, Loss: 0.07443175464868546\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "103f29acf3894b2c8d9c8d1647a3fe57",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/28 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/15, Loss: 0.07125093042850494\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "775ebadf82554730a97e185818c4f86e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/28 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/15, Loss: 0.1371133029460907\n",
      "Train accuracy: 0.9725643992424011\n",
      "Validation accuracy: 0.9268929362297058\n",
      "Test accuracy: 0.939947783946991\n",
      "Train Confusion Matrix:\n",
      "[[971   4]\n",
      " [ 45 766]]\n",
      "Validation Confusion Matrix:\n",
      "[[190   3]\n",
      " [ 25 165]]\n",
      "Test Confusion Matrix:\n",
      "[[201   3]\n",
      " [ 20 159]]\n",
      "Train Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      1.00      0.98       975\n",
      "           1       0.99      0.94      0.97       811\n",
      "\n",
      "    accuracy                           0.97      1786\n",
      "   macro avg       0.98      0.97      0.97      1786\n",
      "weighted avg       0.97      0.97      0.97      1786\n",
      "\n",
      "Validation Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.98      0.93       193\n",
      "           1       0.98      0.87      0.92       190\n",
      "\n",
      "    accuracy                           0.93       383\n",
      "   macro avg       0.93      0.93      0.93       383\n",
      "weighted avg       0.93      0.93      0.93       383\n",
      "\n",
      "Test Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.99      0.95       204\n",
      "           1       0.98      0.89      0.93       179\n",
      "\n",
      "    accuracy                           0.94       383\n",
      "   macro avg       0.95      0.94      0.94       383\n",
      "weighted avg       0.94      0.94      0.94       383\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc0d60d2e7ef4eefbb50527ed4baf790",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/28 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15, Loss: 0.6206620931625366\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb488c109786491cb00fb34ccf745a3e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/28 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/15, Loss: 0.5044087767601013\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0808e77fec69486eadb714f6b14fbb43",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/28 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/15, Loss: 0.3708156645298004\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2479a9aa0ab8401cbad337de59853c27",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/28 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/15, Loss: 0.15974324941635132\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c0f9362317c447d781ede2ec2d92536d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/28 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/15, Loss: 0.2902120053768158\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "41d1337e2678406692f855b2788f34fb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/28 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/15, Loss: 0.3595047891139984\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "04bf5d337e5f4a51a9400353dfc2c501",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/28 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/15, Loss: 0.23786020278930664\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eab9d23c57c041708c9211904dbf52c0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/28 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/15, Loss: 0.23972894251346588\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c52e93dc634044aca3960d780e691f71",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/28 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/15, Loss: 0.0780545026063919\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "02c245d3543f49c2a2f19b851d3b2877",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/28 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/15, Loss: 0.20204302668571472\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d4e587b10cb04e56868fcccfb9b441e1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/28 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/15, Loss: 0.11414393037557602\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d6a2003bd2cf4b28abf556a266fe5724",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/28 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/15, Loss: 0.32714903354644775\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f1a7c17b7159453389bba3ceefa98888",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/28 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/15, Loss: 0.21082381904125214\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4acf40ae566d4af58d4f7a0491485f54",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/28 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/15, Loss: 0.05316583439707756\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3a321d83a1b947b68f82f5df465e8964",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/28 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/15, Loss: 0.10694058984518051\n",
      "Train accuracy: 0.9837626218795776\n",
      "Validation accuracy: 0.9060052037239075\n",
      "Test accuracy: 0.9138381481170654\n",
      "Train Confusion Matrix:\n",
      "[[973   2]\n",
      " [ 27 784]]\n",
      "Validation Confusion Matrix:\n",
      "[[187   6]\n",
      " [ 30 160]]\n",
      "Test Confusion Matrix:\n",
      "[[199   5]\n",
      " [ 28 151]]\n",
      "Train Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.99       975\n",
      "           1       1.00      0.97      0.98       811\n",
      "\n",
      "    accuracy                           0.98      1786\n",
      "   macro avg       0.99      0.98      0.98      1786\n",
      "weighted avg       0.98      0.98      0.98      1786\n",
      "\n",
      "Validation Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.97      0.91       193\n",
      "           1       0.96      0.84      0.90       190\n",
      "\n",
      "    accuracy                           0.91       383\n",
      "   macro avg       0.91      0.91      0.91       383\n",
      "weighted avg       0.91      0.91      0.91       383\n",
      "\n",
      "Test Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.98      0.92       204\n",
      "           1       0.97      0.84      0.90       179\n",
      "\n",
      "    accuracy                           0.91       383\n",
      "   macro avg       0.92      0.91      0.91       383\n",
      "weighted avg       0.92      0.91      0.91       383\n",
      "\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "# Set the hyperparameters for all the models     # TODO: analyze these by model\n",
    "embedding_dict = tokenizer.vocab_size\n",
    "embedding_size = 128\n",
    "hidden_size = 256\n",
    "num_layers = 4\n",
    "num_classes = 2\n",
    "dropout = 0.4\n",
    "learning_rate = 0.0007\n",
    "num_epochs = 15\n",
    "\n",
    "# Train the forwards model\n",
    "# Initialize the model, loss function and optimizer\n",
    "modelFW = CombinedLSTM(embedding_dict, embedding_size, hidden_size, num_layers, num_classes, dropout).to(device)\n",
    "optimizer = optim.Adam(modelFW.parameters(), lr=learning_rate)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    modelFW.train()\n",
    "    for batch in tqdm(fw_train_loader):\n",
    "        tokens, labels = batch\n",
    "        comment_sequence = tokens['input_ids'].to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = modelFW(comment_sequence)\n",
    "        loss = criterion(outputs, labels)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    print(f'Epoch {epoch+1}/{num_epochs}, Loss: {loss.item()}')\n",
    "\n",
    "# Print the results of the forwards model\n",
    "results(modelFW, fw_train_loader, fw_val_loader, fw_test_loader)\n",
    "\n",
    "# Train the backwards model\n",
    "# Initialize the model, loss function and optimizer\n",
    "modelBW = CombinedLSTM(embedding_dict, embedding_size, hidden_size, num_layers, num_classes, dropout).to(device)\n",
    "optimizer = optim.Adam(modelBW.parameters(), lr=learning_rate)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    modelBW.train()\n",
    "    for batch in tqdm(bw_train_loader):\n",
    "        tokens, labels = batch\n",
    "        comment_sequence = tokens['input_ids'].to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = modelBW(comment_sequence)\n",
    "        loss = criterion(outputs, labels)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    print(f'Epoch {epoch+1}/{num_epochs}, Loss: {loss.item()}')\n",
    "\n",
    "# Print the results of the backwards model\n",
    "results(modelBW, bw_train_loader, bw_val_loader, bw_test_loader)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\a_sta\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:83: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.4 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CombinedLSTM(\n",
      "  (embedding): Embedding(30522, 128)\n",
      "  (dropout): Dropout(p=0.4, inplace=False)\n",
      "  (lstm): LSTM(128, 256, batch_first=True, dropout=0.4)\n",
      "  (attention): Linear(in_features=256, out_features=1, bias=True)\n",
      "  (fc): Linear(in_features=256, out_features=2, bias=True)\n",
      ")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'model_images\\\\sequence_combined_lstm.png'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torchviz import make_dot\n",
    "embedding_dict = tokenizer.vocab_size\n",
    "embedding_size = 128\n",
    "hidden_size = 256\n",
    "num_layers = 1\n",
    "num_classes = 2\n",
    "dropout = 0.4\n",
    "learning_rate = 0.0007\n",
    "num_epochs = 15\n",
    "\n",
    "# Initialize the model, loss function and optimizer\n",
    "model = CombinedLSTM(embedding_dict, embedding_size, hidden_size, num_layers, num_classes, dropout).to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "batch = next(iter(fw_train_loader))\n",
    "scores = model(batch[0]['input_ids'])\n",
    "\n",
    "print(model)\n",
    "make_dot(scores, params=dict(list(model.named_parameters()))).render(\"model_images/sequence_combined_lstm\", format=\"png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
